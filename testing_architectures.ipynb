{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/divyayeluri/envs/ml_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import arch_2 as arch # This is the model architecture to use\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Maybe get the data .mat file\n",
    "if not os.path.isfile(\"data.mat\"):\n",
    "    !wget https://www.dropbox.com/s/b1bnrj2f30xe1ns/xq_data_big.mat?dl=0\n",
    "    !mv 'xq_data_big.mat?dl=0' data.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and normalize the training and testing data\n",
    "f = h5py.File(\"data.mat\")\n",
    "data, labels = np.array(f['data']), np.array(f['labels'])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use for the rest of this workflow\n",
    "BATCH_SIZE = 60\n",
    "TEST_SIZE = 3000\n",
    "NCLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels, test_data, test_labels) = data[TEST_SIZE:], labels[TEST_SIZE:], data[:TEST_SIZE], labels[:TEST_SIZE]\n",
    "\n",
    "# Convert labels to one-hot format\n",
    "train_labels = (np.arange(NCLASS) == train_labels).astype(np.float32)\n",
    "test_labels = (np.arange(NCLASS) == test_labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity check to make sure data is not crazy\n",
    "plt.subplot(111).hist(train_data[0].flatten(), bins=20)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract validation set from data\n",
    "VAL_SIZE = int(train_data.shape[0] * 0.1)\n",
    "val_data, train_data = train_data[:VAL_SIZE], train_data[VAL_SIZE:]\n",
    "val_labels, train_labels = train_labels[:VAL_SIZE], train_labels[VAL_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15300, 32738)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to the format specified by the particular architecture we are using\n",
    "train_data = arch.reshape_data(train_data)\n",
    "test_data = arch.reshape_data(test_data)\n",
    "val_data = arch.reshape_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15300, 16369, 2, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining computation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and input / output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch.make_vars_on_cpu(NCLASS)\n",
    "train_data_node = tf.placeholder(tf.float32, [BATCH_SIZE] + list(train_data.shape[1:]))\n",
    "train_label_node = tf.placeholder(tf.float32, [BATCH_SIZE, NCLASS])         \n",
    "test_data_node, test_label_node = tf.constant(test_data, dtype=tf.float32), tf.constant(test_labels, dtype=tf.float32)\n",
    "val_data_node, val_label_node = tf.constant(val_data, dtype=tf.float32), tf.constant(val_labels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses, learning rate, and optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_out = arch.model(val_data_node)\n",
    "val_probs = tf.nn.softmax(val_out)\n",
    "\n",
    "test_out = arch.model(test_data_node)\n",
    "test_probs = tf.nn.softmax(test_out)\n",
    "\n",
    "logits, regularizers = arch.model(train_data_node, train=True)\n",
    "probs = tf.nn.softmax(logits)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=train_label_node))\n",
    "loss += regularizers\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "start_eta = 0.01\n",
    "learning_rate = tf.train.exponential_decay(start_eta, global_step * BATCH_SIZE, train_labels.shape[0], 0.95, staircase=True)\n",
    "update_weights = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.as_default()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check, ensure that things are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, lab = train_data[:BATCH_SIZE], train_labels[:BATCH_SIZE]\n",
    "\n",
    "feed_dict = {train_data_node:dat, train_label_node:lab }\n",
    "_, predictions, l = sess.run([update_weights, probs, loss], feed_dict)\n",
    "\n",
    "err, confusions = utils.error_rate(predictions, lab), utils.confusions(predictions, lab)\n",
    "print(f\"Initial mini-batch err: {err}\")\n",
    "utils.plot_confusions(confusions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train over the first 1/4th of our training set.\n",
    "n_epoch = 1\n",
    "steps = (train_labels.shape[0] // BATCH_SIZE) * n_epoch\n",
    "ls = np.empty(steps)\n",
    "errs = np.empty(steps)\n",
    "val_errs = np.empty(np.ceil(steps / 100).astype(int))\n",
    "\n",
    "for step in range(steps):\n",
    "    # Compute the offset of the current minibatch in the data.\n",
    "    offset = (step * BATCH_SIZE) % (train_labels.shape[0] - BATCH_SIZE) # Should really randomize some\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    feed_dict = {train_data_node: batch_data,\n",
    "                 train_label_node: batch_labels}\n",
    "    # Run the graph and fetch some of the nodes.\n",
    "    _, l, predictions = sess.run(\n",
    "      [update_weights, loss, probs],\n",
    "      feed_dict=feed_dict)\n",
    "    ls[step] = l\n",
    "    errs[step] = utils.error_rate(predictions, batch_labels)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        val_errs[step // 100] = utils.error_rate(val_out.eval(), val_labels)\n",
    "        print('Step %d of %d' % (step, steps))\n",
    "        print(\"Mini-batch loss: {}, error: {}, val error: {}\".format(ls[step], errs[step], val_errs[step // 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, actual = test_probs.eval(), test_label_node.eval()\n",
    "error = utils.error_rate(predicted, actual)\n",
    "confusions = utils.confusions(predicted, actual)\n",
    "print(f\"Test error: {error}\")\n",
    "utils.plot_confusions(confusions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].plot(ls)\n",
    "ax[0].set_xlabel(\"Training Step\")\n",
    "ax[0].set_ylabel(\"Loss (cross-entropy)\")\n",
    "\n",
    "ax[1].plot(errs, label=\"Training Error\")\n",
    "ax[1].scatter(np.arange(val_errs.shape[0]) * 100, val_errs, label=\"Validation Error\", c='k')\n",
    "ax[1].set_xlabel(\"Training Step\")\n",
    "ax[1].set_ylabel(\"Error rate (\\%)\")\n",
    "ax[1].legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
